# =============================================================================
# GPU Workers Deployment for iMeetPro (AI/ML Processing)
# =============================================================================
# NOTE: Only deploy this if you have GPU nodes in your EKS cluster
# =============================================================================
apiVersion: apps/v1
kind: Deployment
metadata:
  name: gpu-worker
  namespace: imeetpro
  labels:
    app: gpu-worker
spec:
  replicas: 1
  selector:
    matchLabels:
      app: gpu-worker
  template:
    metadata:
      labels:
        app: gpu-worker
    spec:
      nodeSelector:
        node-type: gpu
      tolerations:
        - key: "nvidia.com/gpu"
          operator: "Exists"
          effect: "NoSchedule"
      containers:
        - name: gpu-worker
          image: 664418964913.dkr.ecr.ap-south-1.amazonaws.com/imeetpro-prod/backend-gpu:latest
          imagePullPolicy: Always
          command:
            - celery
            - -A
            - config
            - worker
            - -l
            - INFO
            - -Q
            - gpu_tasks
            - --concurrency=2
          envFrom:
            - configMapRef:
                name: backend-config
            - secretRef:
                name: backend-secrets
          resources:
            requests:
              memory: "4Gi"
              cpu: "2000m"
              nvidia.com/gpu: "1"
            limits:
              memory: "8Gi"
              cpu: "4000m"
              nvidia.com/gpu: "1"
          volumeMounts:
            - name: tmp
              mountPath: /tmp
            - name: models
              mountPath: /app/models
      volumes:
        - name: tmp
          emptyDir: {}
        - name: models
          emptyDir: {}
      securityContext:
        runAsNonRoot: false
        runAsUser: 0

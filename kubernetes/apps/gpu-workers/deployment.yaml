# =============================================================================
# GPU Workers Deployment for iMeetPro - Production
# =============================================================================
# Prerequisites:
# 1. GPU nodes with nvidia.com/gpu=true label
# 2. NVIDIA Device Plugin installed:
#    kubectl apply -f https://raw.githubusercontent.com/NVIDIA/k8s-device-plugin/v0.14.1/nvidia-device-plugin.yml
# =============================================================================
apiVersion: apps/v1
kind: Deployment
metadata:
  name: gpu-worker
  namespace: imeetpro
  labels:
    app: gpu-worker
spec:
  replicas: 2
  selector:
    matchLabels:
      app: gpu-worker
  template:
    metadata:
      labels:
        app: gpu-worker
    spec:
      # Schedule on GPU nodes
      nodeSelector:
        nvidia.com/gpu: "true"
      tolerations:
        - key: "nvidia.com/gpu"
          operator: "Exists"
          effect: "NoSchedule"
      containers:
        - name: gpu-worker
          image: 664418964913.dkr.ecr.ap-south-1.amazonaws.com/imeetpro-prod/gpu-worker:latest
          imagePullPolicy: Always
          command:
            - celery
            - -A
            - SampleDB
            - worker
            - -l
            - INFO
            - -Q
            - gpu_tasks,default
            - --concurrency=2
          envFrom:
            - configMapRef:
                name: backend-config
            - secretRef:
                name: backend-secrets
          env:
            - name: NVIDIA_VISIBLE_DEVICES
              value: "all"
            - name: NVIDIA_DRIVER_CAPABILITIES
              value: "compute,utility"
          resources:
            requests:
              memory: "4Gi"
              cpu: "2000m"
              nvidia.com/gpu: "1"
            limits:
              memory: "8Gi"
              cpu: "4000m"
              nvidia.com/gpu: "1"
          volumeMounts:
            - name: tmp
              mountPath: /tmp
            - name: models
              mountPath: /app/models
            - name: dshm
              mountPath: /dev/shm
      volumes:
        - name: tmp
          emptyDir: {}
        - name: models
          emptyDir: {}
        - name: dshm
          emptyDir:
            medium: Memory
            sizeLimit: 2Gi
      securityContext:
        runAsNonRoot: false
        runAsUser: 0
